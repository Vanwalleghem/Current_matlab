{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from skimage import feature\n",
    "from math import sqrt\n",
    "from skimage.morphology import disk, opening\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure, show, axes, sci\n",
    "from matplotlib import colors\n",
    "from thunder import NMF, PCA, RegressionModel, Colorize\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from pyfnnd import apply_all_cells\n",
    "import scipy.io\n",
    "from scipy.stats import pearsonr\n",
    "import math\n",
    "import itertools\n",
    "import glob, os\n",
    "image = Colorize.image\n",
    "from scipy import signal\n",
    "from subprocess import Popen, PIPE\n",
    "import PIL\n",
    "window = signal.gaussian(5, std=1)\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('ticks')\n",
    "plt.ioff()\n",
    "\n",
    "\n",
    "def Spikeinference(img,Mask):\n",
    "    global MeanFluo_ROI_thund\n",
    "    MeanFluo_ROI_thund=img.meanByRegions(Mask).toSeries()\n",
    "    MeanFluo_ROI=img.meanByRegions(Mask).collectAsArray()\n",
    "    n_hat, C_hat, LL, theta_hat=apply_all_cells(np.transpose(MeanFluo_ROI[1][:,0]),disp=0, n_jobs=-1)\n",
    "    scipy.io.savemat('/mnt/downloads/'+savedirectory+'/'+filename+'-ROI_SpikePred.mat', mdict={'n_hat':n_hat,'C_hat':C_hat,'LL':LL,'theta_hat':theta_hat}, oned_as='column', do_compression='true')\n",
    "    np.savetxt('/mnt/downloads/'+savedirectory+'/'+filename+'-segmentation-ROI_Raw.csv',MeanFluo_ROI[1][:,0])\n",
    "    return n_hat, C_hat, LL, theta_hat\n",
    "\n",
    "def NMFCorr(stimparam,NMFH,data_to_analyze,p_value=0.05):\n",
    "    results=[]\n",
    "    lst = np.asarray(list(itertools.product([0, 1], repeat=stimparam.shape[0])))\n",
    "    corrMat=np.zeros((Mask.shape[0],Mask.shape[1]),dtype=np.float32)\n",
    "    for k in range(0,NMFH.shape[0]):\n",
    "        result=[]\n",
    "        ccr=[]\n",
    "        pvalues=[]\n",
    "        for j in range(1,lst.shape[0]):\n",
    "            combination=np.zeros((1,NMFH.shape[1]),dtype=np.int16);\n",
    "            for i in np.transpose(np.nonzero(lst[j])[0]):\n",
    "                combination+=stimparam[i]\n",
    "            cc,pval=pearsonr(NMFH[k,:],combination[0])\n",
    "            ccr.append(cc)\n",
    "            pvalues.append(pval)\n",
    "        result.append(ccr[np.argmin(pvalues)])\n",
    "        result.append(pvalues[np.argmin(pvalues)])\n",
    "        result.append(lst[np.argmin(pvalues)])\n",
    "        results.append(result)\n",
    "        combination=np.zeros((1,NMFH.shape[1]),dtype=np.int16);\n",
    "        if pvalues[np.argmin(pvalues)]<p_value:\n",
    "            for i in np.transpose(np.nonzero(lst[np.argmin(pvalues)])[0]):\n",
    "                combination+=stimparam[i]\n",
    "            if np.any(combination):\n",
    "                corrs = data_to_analyze.correlate(combination)\n",
    "                corrMat = corrs.collectValuesAsArray()\n",
    "                Masktemp=Mask.astype(np.float32).copy()\n",
    "                for idx in xrange(0,corrMat.shape[0]):\n",
    "                    Masktemp[Masktemp==idx+1]=corrMat[idx]\n",
    "                fig = figure(dpi=300)\n",
    "                plt.imshow(Masktemp)\n",
    "                plt.savefig('/mnt/downloads/'+savedirectory+'/'+filename+'-Correlation of significant NMF-'+str(k)+' combination.png', dpi=300, bbox_inches='tight')\n",
    "                scipy.io.savemat('/mnt/downloads/'+savedirectory+'/'+filename+'-Correlation of significant NMF-'+str(k)+'.mat', mdict={'correlations':corrMat}, oned_as='column', do_compression='true')\n",
    "                plt.close(\"all\")\n",
    "    with open('/mnt/downloads/'+savedirectory+'/'+filename+'-NMF_Spikes_CorrCoef.txt', 'w') as outfile:\n",
    "        i=0\n",
    "        for data_slice in results:\n",
    "            outfile.write ('NMF-'+str(i)+' CorrCoef : ' + np.array_str(data_slice[0]).rjust(10)+' p-value : '+ np.array_str(data_slice[1]) +' Combination of features : '+ np.array_str(data_slice[2]))\n",
    "            outfile.write('\\n')\n",
    "            i+=1\n",
    "    return\n",
    "\n",
    "def NMF_spikes(n_hat,stimparam,numcomp=18):\n",
    "    global data_to_analyze\n",
    "    global model\n",
    "    np.save('/mnt/downloads/'+directory+'/nhatFullData.npy',n_hat)\n",
    "    data_to_analyze=tsc.loadSeries('/mnt/downloads/'+directory+'/nhatFullData.npy', inputFormat='npy', minPartitions=300)\n",
    "    model = NMF(k=numcomp, maxIter=100,tol=0.0001,reconHist='final').fit(data_to_analyze)\n",
    "    imgs = model.w.collectAsArray()\n",
    "    scipy.io.savemat('/mnt/downloads/'+savedirectory+'/'+filename+'-NMF_Spikes.mat', mdict={'W':imgs[1],'H':model.h.T,'ReconErr':model.reconErr}, oned_as='column', do_compression='true')\n",
    "    scores=[]\n",
    "    for i in xrange(0,imgs[1].shape[1]):\n",
    "        Masktemp=Mask.astype(np.float32).copy()\n",
    "        for idx in xrange(0,imgs[1].shape[0]):\n",
    "            Masktemp[Masktemp==idx+1]=imgs[1][idx][i]\n",
    "        scores.append(Masktemp)\n",
    "    for i in xrange(0,model.h.T.shape[1]):\n",
    "        fig = figure(dpi=300)\n",
    "        plt.subplots(1, 2, sharex=True, sharey=True)\n",
    "        plt.subplot(1, 2, 1);\n",
    "        plt.plot(model.h.T[:,i])\n",
    "        plt.subplot(1, 2, 2);\n",
    "        plt.imshow(scores[i])\n",
    "        plt.savefig('/mnt/downloads/'+savedirectory+'/'+filename+'-NMF-Spikes-'+str(i)+'.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close(\"all\")\n",
    "    NMFCorr(stimparam,np.transpose(model.h.T),data_to_analyze)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory='Tonotropy2'\n",
    "savedirectory='TonotropyResults2'\n",
    "os.chdir('/mnt/downloads/'+directory+'/')\n",
    "p=Popen(['ls'], shell=False, stdout=PIPE, close_fds=True).stdout.readlines()\n",
    "filelist=[]\n",
    "for filename in p:\n",
    "    if filename.startswith('GC'):\n",
    "        filelist.append(filename.rstrip('\\n'))\n",
    "for i,filename in enumerate(filelist):\n",
    "    if i==1:\n",
    "        img = tsc.loadImages('/mnt/downloads/'+directory+'/'+str(i+1)+'/', inputFormat='tif')\n",
    "        Mask = PIL.Image.open('/mnt/downloads/'+directory+'/Mask_'+filename)\n",
    "        Mask=np.asarray(Mask,dtype=np.uint16)\n",
    "        n_hat, C_hat, LL, theta_hat = Spikeinference(img,Mask)\n",
    "        model=NMF_spikes(n_hat,aud8freq)\n",
    "        results = RegressionModel.load(aud8freq, 'linear').fit(data_to_analyze)\n",
    "        betas=results.select('betas').collectValuesAsArray()\n",
    "        rsq=results.select('stats').collectValuesAsArray()\n",
    "        scipy.io.savemat('/mnt/downloads/'+savedirectory+'/'+filename+'-linreg.mat', mdict={'betas':betas,'rsq':rsq}, oned_as='column', do_compression='true')\n",
    "        plt.close(\"all\")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory='Tonotropy2/neo'\n",
    "savedirectory='TonotropyResults2'\n",
    "os.chdir('/mnt/downloads/'+directory+'/')\n",
    "p=Popen(['ls'], shell=False, stdout=PIPE, close_fds=True).stdout.readlines()\n",
    "filelist=[]\n",
    "for filename in p:\n",
    "    if filename.startswith('neo'):\n",
    "        filelist.append(filename.rstrip('\\n'))\n",
    "for i,filename in enumerate(filelist):\n",
    "    if i>0:\n",
    "        img = tsc.loadImages('/mnt/downloads/'+directory+'/'+str(i+1)+'/', inputFormat='tif')\n",
    "        Mask = PIL.Image.open('/mnt/downloads/'+directory+'/Mask_'+filename)\n",
    "        Mask=np.asarray(Mask,dtype=np.uint16)\n",
    "        n_hat, C_hat, LL, theta_hat = Spikeinference(img,Mask)\n",
    "        model=NMF_spikes(n_hat,aud8freq)\n",
    "        results = RegressionModel.load(aud8freq, 'linear').fit(data_to_analyze)\n",
    "        betas=results.select('betas').collectValuesAsArray()\n",
    "        rsq=results.select('stats').collectValuesAsArray()\n",
    "        scipy.io.savemat('/mnt/downloads/'+savedirectory+'/'+filename+'-linreg.mat', mdict={'betas':betas,'rsq':rsq}, oned_as='column', do_compression='true')\n",
    "        plt.close(\"all\")\n",
    "        results = RegressionModel.load(aud8freq, 'linear').fit(MeanFluo_ROI_thund)\n",
    "        betas=results.select('betas').collectValuesAsArray()\n",
    "        rsq=results.select('stats').collectValuesAsArray()\n",
    "        scipy.io.savemat('/mnt/downloads/'+savedirectory+'/'+filename+'-RAW-linreg.mat', mdict={'betas':betas,'rsq':rsq}, oned_as='column', do_compression='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aud8freq=np.zeros((8,700),dtype=np.int);\n",
    "aud8freq[0,21:21+5]=1;\n",
    "aud8freq[0,406:406+5]=1;\n",
    "aud8freq[0,611:611+5]=1;\n",
    "\n",
    "aud8freq[1,46:46+5]=1;\n",
    "aud8freq[1,381:381+5]=1;\n",
    "aud8freq[1,536:536+5]=1;\n",
    "\n",
    "aud8freq[2,71:71+5]=1;\n",
    "aud8freq[2,356:356+5]=1;\n",
    "aud8freq[2,511:511+5]=1;\n",
    "\n",
    "aud8freq[3,96:96+5]=1;\n",
    "aud8freq[3,331:331+5]=1;\n",
    "aud8freq[3,561:561+5]=1;\n",
    "\n",
    "aud8freq[4,121:121+5]=1;\n",
    "aud8freq[4,306:306+5]=1;\n",
    "aud8freq[4,486:486+5]=1;\n",
    "\n",
    "aud8freq[5,146:146+5]=1;\n",
    "aud8freq[5,281:281+5]=1;\n",
    "aud8freq[5,586:586+5]=1;\n",
    "\n",
    "aud8freq[6,171:171+5]=1;\n",
    "aud8freq[6,256:256+5]=1;\n",
    "aud8freq[6,461:461+5]=1;\n",
    "\n",
    "aud8freq[7,196:196+5]=1;\n",
    "aud8freq[7,231:231+5]=1;\n",
    "aud8freq[7,636:636+5]=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MeanFluo_ROI_thund=MeanFluo_ROI_thund.toSeries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory='Tonotropy2'\n",
    "savedirectory='TonotropyResults2'\n",
    "os.chdir('/mnt/downloads/'+directory+'/')\n",
    "p=Popen(['ls'], shell=False, stdout=PIPE, close_fds=True).stdout.readlines()\n",
    "filelist=[]\n",
    "for filename in p:\n",
    "    if filename.startswith('GC'):\n",
    "        filelist.append(filename.rstrip('\\n'))\n",
    "for i,filename in enumerate(filelist):\n",
    "    img = tsc.loadImages('/mnt/downloads/'+directory+'/'+str(i+1)+'/', inputFormat='tif')\n",
    "    Mask = PIL.Image.open('/mnt/downloads/'+directory+'/Mask_'+filename)\n",
    "    Mask=np.asarray(Mask,dtype=np.uint16)\n",
    "    MeanFluo_ROI_thund=img.meanByRegions(Mask).toSeries()\n",
    "    results = RegressionModel.load(aud8freq, 'linear').fit(MeanFluo_ROI_thund)\n",
    "    betas=results.select('betas').collectValuesAsArray()\n",
    "    rsq=results.select('stats').collectValuesAsArray()\n",
    "    scipy.io.savemat('/mnt/downloads/'+savedirectory+'/'+filename+'-RAW-linreg.mat', mdict={'betas':betas,'rsq':rsq}, oned_as='column', do_compression='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory='Tonotropy2'\n",
    "savedirectory='TonotropyResults2'\n",
    "os.chdir('/mnt/downloads/'+directory+'/')\n",
    "p=Popen(['ls'], shell=False, stdout=PIPE, close_fds=True).stdout.readlines()\n",
    "filelist=[]\n",
    "for filename in p:\n",
    "    if filename.startswith('GC'):\n",
    "        filelist.append(filename.rstrip('\\n'))\n",
    "for i,filename in enumerate(filelist):\n",
    "    img = tsc.loadImages('/mnt/downloads/'+directory+'/'+str(i+1)+'/', inputFormat='tif')\n",
    "    Mask = PIL.Image.open('/mnt/downloads/'+directory+'/Mask_'+filename)\n",
    "    Mask=np.asarray(Mask,dtype=np.uint16)\n",
    "    MeanFluo_ROI_thund=img.meanByRegions(Mask).toSeries()\n",
    "    results = RegressionModel.load(aud8freq, 'linear').fit(MeanFluo_ROI_thund)\n",
    "    betas=results.select('betas').collectValuesAsArray()\n",
    "    rsq=results.select('stats').collectValuesAsArray()\n",
    "    scipy.io.savemat('/mnt/downloads/'+savedirectory+'/'+filename+'-RAW-linreg.mat', mdict={'betas':betas,'rsq':rsq}, oned_as='column', do_compression='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 700)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aud8freq2=np.zeros((9,701),dtype=np.int);\n",
    "aud8freq2[1,22:24+1]=1;\n",
    "aud8freq2[1,407:409+1]=1;\n",
    "aud8freq2[1,611:613+1]=1;\n",
    "\n",
    "aud8freq2[2,47:49+1]=1;\n",
    "aud8freq2[2,383:385+1]=1;\n",
    "aud8freq2[2,534:536+1]=1;\n",
    "\n",
    "aud8freq2[3,71:73+1]=1;\n",
    "aud8freq2[3,357:359+1]=1;\n",
    "aud8freq2[3,507:509+1]=1;\n",
    "\n",
    "aud8freq2[4,97:99+1]=1;\n",
    "aud8freq2[4,330:332+1]=1;\n",
    "aud8freq2[4,556:558+1]=1;\n",
    "\n",
    "aud8freq2[5,121:123+1]=1;\n",
    "aud8freq2[5,306:308+1]=1;\n",
    "aud8freq2[5,487:490+1]=1;\n",
    "\n",
    "aud8freq2[6,146:149+1]=1;\n",
    "aud8freq2[6,278:280+1]=1;\n",
    "aud8freq2[6,586:589+1]=1;\n",
    "\n",
    "aud8freq2[7,167:169+1]=1;\n",
    "aud8freq2[7,254:256+1]=1;\n",
    "aud8freq2[7,469:471+1]=1;\n",
    "\n",
    "aud8freq2[8,190:193+1]=1;\n",
    "aud8freq2[8,229:231+1]=1;\n",
    "aud8freq2[8,646:648+1]=1;\n",
    "aud8freq2=np.delete(aud8freq2, 0, 1)\n",
    "aud8freq2=np.delete(aud8freq2, 0, 0)\n",
    "aud8freq2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory='Tonotropy'\n",
    "savedirectory='TonotropyResults'\n",
    "os.chdir('/mnt/downloads/'+directory+'/')\n",
    "p=Popen(['ls'], shell=False, stdout=PIPE, close_fds=True).stdout.readlines()\n",
    "filelist=[]\n",
    "for filename in p:\n",
    "    if filename.startswith('GC'):\n",
    "        filelist.append(filename.rstrip('\\n'))\n",
    "for i,filename in enumerate(filelist):    \n",
    "    img = tsc.loadImages('/mnt/downloads/'+directory+'/'+str(i+1)+'/', inputFormat='tif')\n",
    "    Mask = PIL.Image.open('/mnt/downloads/'+directory+'/Mask_'+filename)\n",
    "    Mask=np.asarray(Mask,dtype=np.uint16)\n",
    "    n_hat, C_hat, LL, theta_hat = Spikeinference(img,Mask)\n",
    "    model=NMF_spikes(n_hat,aud8freq2)\n",
    "    results = RegressionModel.load(aud8freq2, 'linear').fit(data_to_analyze)\n",
    "    betas=results.select('betas').collectValuesAsArray()\n",
    "    rsq=results.select('stats').collectValuesAsArray()\n",
    "    scipy.io.savemat('/mnt/downloads/'+savedirectory+'/'+filename+'-linreg.mat', mdict={'betas':betas,'rsq':rsq}, oned_as='column', do_compression='true')\n",
    "    plt.close(\"all\")\n",
    "    results = RegressionModel.load(aud8freq2, 'linear').fit(MeanFluo_ROI_thund)\n",
    "    betas=results.select('betas').collectValuesAsArray()\n",
    "    rsq=results.select('stats').collectValuesAsArray()\n",
    "    scipy.io.savemat('/mnt/downloads/'+savedirectory+'/'+filename+'-RAW-linreg.mat', mdict={'betas':betas,'rsq':rsq}, oned_as='column', do_compression='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory='Tonotropy'\n",
    "savedirectory='TonotropyResults'\n",
    "os.chdir('/mnt/downloads/'+directory+'/')\n",
    "p=Popen(['ls'], shell=False, stdout=PIPE, close_fds=True).stdout.readlines()\n",
    "filelist=[]\n",
    "for filename in p:\n",
    "    if filename.startswith('GC'):\n",
    "        filelist.append(filename.rstrip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168459, 700)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i,filename in enumerate(filelist):\n",
    "    if i==0:\n",
    "        SegmentData=np.loadtxt('/mnt/downloads/'+savedirectory+'/'+filename+'-segmentation-ROI_Raw.csv')\n",
    "    else:\n",
    "        tempseg=np.loadtxt('/mnt/downloads/'+savedirectory+'/'+filename+'-segmentation-ROI_Raw.csv')\n",
    "        SegmentData=np.concatenate((SegmentData,tempseg),axis=1)\n",
    "SegmentData=np.transpose(SegmentData)\n",
    "SegmentData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('/mnt/downloads/'+directory+'/SegmentDataFull.npy',SegmentData)\n",
    "data_to_analyze=tsc.loadSeries('/mnt/downloads/'+directory+'/SegmentDataFull.npy', inputFormat='npy', minPartitions=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_to_analyze=tsc.loadSeries('/mnt/downloads/'+directory+'/SegmentDataFull.npy', inputFormat='npy', minPartitions=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series\n",
       "nrecords: None (inspect to compute)\n",
       "dtype: float64\n",
       "dims: None (inspect to compute)\n",
       "index: None (inspect to compute)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_analyze.cache()\n",
    "data_to_analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = NMF(k=30, maxIter=200,tol=0.0001,reconHist='final').fit(data_to_analyze)\n",
    "imgs = model.w.collectAsArray()\n",
    "scipy.io.savemat('/mnt/downloads/'+savedirectory+'/SegmentFull-NMF.mat', mdict={'W':imgs[1],'H':model.h.T,'ReconErr':model.reconErr}, oned_as='column', do_compression='true')\n",
    "scores=[]\n",
    "for i in xrange(0,model.h.T.shape[1],3):\n",
    "    fig = figure(dpi=300)\n",
    "    plt.plot(model.h.T[:,i:i+3])\n",
    "    plt.savefig('/mnt/downloads/'+savedirectory+'/SegmentFull-NMF-'+str(i)+'.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = RegressionModel.load(aud8freq, 'linear').fit(data_to_analyze)\n",
    "betas=results.select('betas').collectValuesAsArray()\n",
    "rsq=results.select('stats').collectValuesAsArray()\n",
    "scipy.io.savemat('/mnt/downloads/'+savedirectory+'/SegmentFull-linreg.mat', mdict={'betas':betas,'rsq':rsq}, oned_as='column', do_compression='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-7748cbedc73d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mMeanFluo_ROI\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_to_analyze\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectValuesAsArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mMeanFluo_ROI\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "MeanFluo_ROI=data_to_analyze.collectValuesAsArray()\n",
    "MeanFluo_ROI.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_hat, C_hat, LL, theta_hat=apply_all_cells(MeanFluo_ROI,disp=0, n_jobs=-1)\n",
    "scipy.io.savemat('/mnt/downloads/'+savedirectory+'/'+filename+'-ROI_SpikePred.mat', mdict={'n_hat':n_hat,'C_hat':C_hat,'LL':LL,'theta_hat':theta_hat}, oned_as='column', do_compression='true')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scipy.io.savemat('/mnt/downloads/'+savedirectory+'/SegmentFull-RAW-spikes.mat', mdict={'InferedSpikes':n_hat}, oned_as='column', do_compression='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('/mnt/downloads/'+directory+'/nhatFullData.npy',n_hat)\n",
    "n_hat_thund=tsc.loadSeries('/mnt/downloads/'+directory+'/nhatFullData.npy', inputFormat='npy', minPartitions=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = RegressionModel.load(aud8freq2, 'linear').fit(n_hat_thund)\n",
    "betas=results.select('betas').collectValuesAsArray()\n",
    "rsq=results.select('stats').collectValuesAsArray()\n",
    "scipy.io.savemat('/mnt/downloads/'+savedirectory+'/SegmentFull-Spikes-linreg.mat', mdict={'betas-spikes':betas,'rsq-spikes':rsq}, oned_as='column', do_compression='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = NMF(k=30, maxIter=200,tol=0.0001,reconHist='final').fit(n_hat_thund)\n",
    "imgs = model.w.collectAsArray()\n",
    "scipy.io.savemat('/mnt/downloads/'+savedirectory+'/SegmentFull-NMF.mat', mdict={'W-spikes':imgs[1],'H-spikes':model.h.T,'ReconErr-spikes':model.reconErr}, oned_as='column', do_compression='true')\n",
    "scores=[]\n",
    "for i in xrange(0,model.h.T.shape[1],3):\n",
    "    fig = figure(dpi=300)\n",
    "    plt.plot(model.h.T[:,i:i+3])\n",
    "    plt.savefig('/mnt/downloads/'+savedirectory+'/SegmentFull-spikes-NMF-'+str(i)+'.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168459"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_analyze.nrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     4,     34,     66, ..., 168295, 168303, 168308])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_select=data_to_analyze.selectByIndex(idx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(4==idx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_select=data_to_analyze._constructor(data_to_analyze.rdd.filter(lambda (k, v): np.any(k==idx[0]))).__finalize__(data_to_analyze)._resetCounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11849"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_select.nrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = NMF(k=30, maxIter=200,tol=0.0001,reconHist='final').fit(data_select)\n",
    "imgs = model.w.collectAsArray()\n",
    "scipy.io.savemat('/mnt/downloads/'+savedirectory+'/SegmentFull-NMF.mat', mdict={'W':imgs[1],'H':model.h.T,'ReconErr':model.reconErr}, oned_as='column', do_compression='true')\n",
    "scores=[]\n",
    "for i in xrange(0,model.h.T.shape[1],3):\n",
    "    fig = figure(dpi=300)\n",
    "    plt.plot(model.h.T[:,i:i+3])\n",
    "    plt.savefig('/mnt/downloads/'+savedirectory+'/SegmentFull-NMF-'+str(i)+'.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.io.savemat('/mnt/downloads/'+savedirectory+'/SegmentFull-index_filt.mat', mdict={'index':idx[0]}, oned_as='column', do_compression='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
